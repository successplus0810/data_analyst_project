{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n",
      "Sheet 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32md:\\python\\claim_pack_python\\venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:385\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 385\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_range\u001b[39m.\u001b[39;49mindex(new_key)\n\u001b[0;32m    386\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\python\\cs_scan_summarizer\\test.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/python/cs_scan_summarizer/test.ipynb#W4sZmlsZQ%3D%3D?line=425'>426</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,count_sheets_excel_file\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/python/cs_scan_summarizer/test.ipynb#W4sZmlsZQ%3D%3D?line=426'>427</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSheet \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/python/cs_scan_summarizer/test.ipynb#W4sZmlsZQ%3D%3D?line=427'>428</a>\u001b[0m     supp_num,supp_desc,vendor_num,supp_number_filter,claim_number,gst,clm_start,clm_end,dept,item_unique,item_list_dict,classify_state,file_path_excel,file_path_email \u001b[39m=\u001b[39m item_gst(i)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/python/cs_scan_summarizer/test.ipynb#W4sZmlsZQ%3D%3D?line=428'>429</a>\u001b[0m     df_sales \u001b[39m=\u001b[39m df_sales_data(item_list_dict,classify_state,supp_number_filter)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/python/cs_scan_summarizer/test.ipynb#W4sZmlsZQ%3D%3D?line=429'>430</a>\u001b[0m     df_item_ref,df_state_ref,df_ref,df_sales_daily,list_data_sales,list_remove_sales  \u001b[39m=\u001b[39m cd_ref(df_sales,supp_number_filter)\n",
      "\u001b[1;32md:\\python\\cs_scan_summarizer\\test.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/python/cs_scan_summarizer/test.ipynb#W4sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     supp_num \u001b[39m=\u001b[39m supp_number_filter\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/python/cs_scan_summarizer/test.ipynb#W4sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m     df_gst \u001b[39m=\u001b[39m df_gst[df_gst[\u001b[39m'\u001b[39m\u001b[39mSUPP_IDNT\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m(supp_number_filter)]\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/python/cs_scan_summarizer/test.ipynb#W4sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m gst \u001b[39m=\u001b[39m df_gst[\u001b[39m'\u001b[39;49m\u001b[39mCML_COST_GST_RATE_PCT\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m]\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/python/cs_scan_summarizer/test.ipynb#W4sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m gst \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(gst)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/python/cs_scan_summarizer/test.ipynb#W4sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m claim_number \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mgst\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32md:\\python\\claim_pack_python\\venv\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32md:\\python\\claim_pack_python\\venv\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1068\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1069\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1070\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32md:\\python\\claim_pack_python\\venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:387\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range\u001b[39m.\u001b[39mindex(new_key)\n\u001b[0;32m    386\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 387\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    389\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import snowflake.connector as sf\n",
    "import os\n",
    "import xlwings as xw\n",
    "from xlwings.constants import DeleteShiftDirection\n",
    "import datetime\n",
    "import numpy as np\n",
    "import win32com.client as win32\n",
    "from pywintypes import com_error\n",
    "import math\n",
    "\n",
    "##########################' \n",
    "# Analyst fill\n",
    "vendor_name = 'ABCCC'\n",
    "analyst_name = 'DN'\n",
    "date_batch = '20210801'\n",
    "#######################\n",
    "\n",
    "config_coles = r\"config.json\"\n",
    "config_coles_clean = r\"config2.json\"\n",
    "\n",
    "file_sql_summ = r\"summarizer.sql\"\n",
    "file_sql_summ_vendor = r\"summarizer_vendor.sql\"\n",
    "file_sql_cd_ref = r\"cd_ref.sql\"\n",
    "file_sql_dept = r\"dept.sql\"\n",
    "file_sql_gst = r\"gst.sql\"\n",
    "file_sql_cd_ref_listagg = r\"cd_ref_listagg.sql\"\n",
    "file_sql_cd_ref_listagg_item = r\"cd_ref_listagg_item.sql\"\n",
    "file_sql_pct = r\"count_pct.sql\"\n",
    "\n",
    "current_dir = 'D:\\\\python\\\\cs_scan_summarizer'\n",
    "os.chdir('D:\\\\python\\\\cs_scan_summarizer')\n",
    "\n",
    "path_excel = r\"CS_SCAN_Vendorname_Analyst_Date.xlsx\"\n",
    "path_import_item = 'item_import.xlsx'\n",
    "# vendor_name = (input('Input vendor name : ')).upper()\n",
    "# analyst_name = (input('Input analyst name. Example: CT. Your answer is ')).upper()\n",
    "# date_batch = input('Input date batch. Example: 20230207. Your answer is ')\n",
    "iconPath_email = r\"C:\\Program Files\\Microsoft Office\\root\\Office16\\OUTLOOK.EXE\"\n",
    "iconPath_excel = r\"C:\\Program Files\\Microsoft Office\\root\\Office16\\EXCEL.EXE\"\n",
    "\n",
    "\n",
    "path_export_final = 'CS_SCAN_'+vendor_name+'_'+analyst_name+'_'+date_batch+'.xlsx'\n",
    "path_export_final_xlsb = 'CS_SCAN_'+vendor_name+'_'+analyst_name+'_'+date_batch+'.xlsb'\n",
    "path_vba = 'CS_SCAN_vendorname_analyst_yyyymmdd.xlsb'\n",
    "\n",
    "def set_up(config):\n",
    "    \"\"\"Set up connection to SnowFlake\"\"\"\n",
    "    config = json.loads(open(config).read())\n",
    "    account = config['snowflake']['account']\n",
    "    user = config['snowflake']['user']\n",
    "    warehouse = config['snowflake']['warehouse']\n",
    "    role = config['snowflake']['role']\n",
    "    database = config['snowflake']['database']\n",
    "    schema = config['snowflake']['schema']\n",
    "    password = config['snowflake']['password']\n",
    "    auth = config['snowflake']['authenticator']\n",
    "\n",
    "    conn = sf.connect(user=user, password=password, account=account, authenticator=auth,\n",
    "                      warehouse=warehouse, role=role, database=database, schema=schema)\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    return cursor\n",
    "def connect_sql(cursor,file_sql,item_code,start_date = '',end_date='',var_1='',var_2 = '',var_3 = ''):\n",
    "    try:\n",
    "        cursor.execute((open(file_sql).read()).format(item_code,start_date,end_date,var_1,var_2,var_3))\n",
    "        all_rows = cursor.fetchall()\n",
    "        field_names = [i[0] for i in cursor.description]\n",
    "    finally:\n",
    "        # conn.close()\n",
    "        pass\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    try:\n",
    "        df.columns = field_names\n",
    "    except ValueError:\n",
    "        return pd.DataFrame(columns=field_names)\n",
    "    return df\n",
    "   \n",
    "def convert_to_input_sql(num_list):\n",
    "    num_list_final = ''\n",
    "    # print('SUPP LIST',supp_num_list)\n",
    "    for num_list in num_list:\n",
    "        num_list_final = num_list_final + \"'\" + num_list + \"',\"\n",
    "    return num_list_final[:-1]\n",
    "\n",
    "def convert_to_input_function(num_list):\n",
    "    num_list_final = ''\n",
    "    # print('SUPP LIST',supp_num_list)\n",
    "    for num_list in num_list:\n",
    "        num_list_final = num_list_final + num_list + ','\n",
    "    return num_list_final[:-1]\n",
    "\n",
    "def item_gst(i):\n",
    "    df = pd.read_excel(path_import_item,sheet_name=str(i))\n",
    "    df['ITEM_IDNT'] = df['ITEM_IDNT'].astype(str)\n",
    "    df['ITEM_IDNT'] = df['ITEM_IDNT'].str.strip() \n",
    "    item_unique = df['ITEM_IDNT'].drop_duplicates().tolist()\n",
    "    item_unique = \"','\".join(item_unique)\n",
    "    df['STATE'] = df['STATE'].str.strip()\n",
    "    clm_start = df['CLM_START'][0]\n",
    "    clm_end = df['CLM_END'][0]\n",
    "    supp_number_filter = df['VENDOR_NUM'][0]\n",
    "    df_gst = connect_sql(cursor,file_sql=file_sql_gst, item_code=item_unique)\n",
    "    if np.isnan(supp_number_filter):\n",
    "        supp_num = df_gst['SUPP_IDNT'][0]\n",
    "    else:\n",
    "        supp_num = supp_number_filter\n",
    "        df_gst = df_gst[df_gst['SUPP_IDNT'] == str(supp_number_filter)].reset_index(drop=True)\n",
    "    gst = df_gst['CML_COST_GST_RATE_PCT'][0]\n",
    "    gst = int(gst)\n",
    "    claim_number = f'{i}_{gst}'\n",
    "    dept = df_gst['DEPT_IDNT'][0]\n",
    "    supp_desc = df_gst['SUPP_DESC'][0]\n",
    "    vendor_num = df_gst['VENDOR_NUM'][0]\n",
    "    classify_state = df['CLASSIFY_STATE'][0]\n",
    "    pct = df['PERCENTAGE'][0]\n",
    "    file_path_excel = df['EXCEL_PATH'][0]\n",
    "    file_path_email = df['EMAIL_PATH'][0]\n",
    "    if np.isnan(pct) == False:\n",
    "        df_pct = connect_sql(cursor, file_sql_pct, item_code=item_unique, start_date= clm_start , end_date= clm_end )\n",
    "        df = df.merge( right= df_pct , how = 'left',on ='ITEM_IDNT')\n",
    "        df['RRP'] = (100- df['PERCENTAGE'].astype('float') )/ 100 * df['NORMAL_PRICE'].astype('float')\n",
    "    else:\n",
    "        pass\n",
    "    if classify_state.lower() == 'state':\n",
    "        # item_list_dict = df.set_index(['ITEM_IDNT','STATE'])[['RRP','SCANRATE']].to_dict('index')\n",
    "        df = df[['ITEM_IDNT','STATE','RRP','SCANRATE']].drop_duplicates()\n",
    "        df['SCANRATE'] = df['SCANRATE'].round(2)\n",
    "        df['RRP'] = df['RRP'].round(2)\n",
    "        df = df.groupby(by = ['STATE','RRP','SCANRATE'])['ITEM_IDNT'].agg(list).to_frame().reset_index()\n",
    "        df['ITEM_IDNT'] = df['ITEM_IDNT'].apply(lambda x : convert_to_input_function(x))\n",
    "        df = df.groupby(by = ['RRP','SCANRATE','ITEM_IDNT'])['STATE'].agg(list).to_frame().reset_index()\n",
    "        df['STATE'] = df['STATE'].apply(lambda x : convert_to_input_sql(x))\n",
    "        item_list_dict = df.set_index(['ITEM_IDNT','STATE'])[['RRP','SCANRATE']].to_dict('index')\n",
    "        for key,value in item_list_dict.items():\n",
    "            item_list_dict[key] = [item_list_dict[key]['RRP']] + [item_list_dict[key]['SCANRATE']] \n",
    "        print(df)\n",
    "        print(item_list_dict)\n",
    "    else:\n",
    "        # item_list_dict = df.set_index('ITEM_IDNT')[['RRP','SCANRATE']].to_dict('index')\n",
    "        df = df[['ITEM_IDNT','RRP','SCANRATE']].drop_duplicates()\n",
    "        df['SCANRATE'] = df['SCANRATE'].round(2)\n",
    "        df['RRP'] = df['RRP'].round(2)\n",
    "        df = df.groupby(by = ['RRP','SCANRATE'])['ITEM_IDNT'].agg(list).to_frame().reset_index()\n",
    "        df['ITEM_IDNT'] = df['ITEM_IDNT'].apply(lambda x : convert_to_input_function(x))\n",
    "        item_list_dict = df.set_index('ITEM_IDNT')[['RRP','SCANRATE']].to_dict('index')\n",
    "        for key,value in item_list_dict.items():\n",
    "            item_list_dict[key] = [item_list_dict[key]['RRP']] + [item_list_dict[key]['SCANRATE']] \n",
    "        print(df)\n",
    "        print(item_list_dict)\n",
    "    for key,value in item_list_dict.items():\n",
    "        if gst == 10:\n",
    "            item_list_dict[key][0] = item_list_dict[key][0] /1.1 \n",
    "        else:\n",
    "            pass   \n",
    "    return supp_num,supp_desc,vendor_num,supp_number_filter,claim_number,gst,clm_start,clm_end,dept,item_unique,item_list_dict,classify_state,file_path_excel,file_path_email\n",
    "\n",
    "def writer_excel(data,remove,number_sheet,path_export_final):\n",
    "    # data = list_data, remove = list_remove,number_sheet= str(index_promo)+'_'+str(gst),path_export_final=path_export_final\n",
    "    #select sheet\n",
    "    sheet_df_mapping = {number_sheet: data}\n",
    "    sheet_df_remove  = {number_sheet: remove}\n",
    "    # Open Excel in background\n",
    "    with xw.App(visible=False) as app:\n",
    "        wb = app.books.open(path_export_final)\n",
    "        # List of current worksheet names\n",
    "        current_sheets = [sheet.name for sheet in wb.sheets]\n",
    "        # Iterate over sheet/df mapping\n",
    "        # If sheet already exist, overwrite current cotent. Else, add new sheet\n",
    "        print('start copy data')\n",
    "        for sheet_name in sheet_df_mapping.keys():\n",
    "            if sheet_name in current_sheets:\n",
    "                for df_data in data :\n",
    "                    wb.sheets(sheet_name).range(df_data['cell_export']).options(index=False,header=False).value = df_data['df']\n",
    "            else:\n",
    "                'Name of sheet cannot be found in Excel file, please check again'\n",
    "        print('done copy data')\n",
    "        print('start delete rows')\n",
    "        for sheet_name in sheet_df_remove.keys():\n",
    "            if sheet_name in current_sheets:\n",
    "                for df_remove in remove :\n",
    "                    # wb.sheets(sheet_name).range(df_cell['cell_export']).options(index=False,header=False).value = df_cell['df']\n",
    "                    length_start = df_remove['length_start'] + df_remove['count_df']\n",
    "                    range_length_to_remove = str(length_start)+':'+ str(df_remove['length_end'])\n",
    "                    wb.sheets(sheet_name).range(range_length_to_remove).api.Delete(DeleteShiftDirection.xlShiftUp)\n",
    "            else:\n",
    "                'Name of sheet cannot be found in Excel file, please check again'\n",
    "        print('done delete rows')\n",
    "        wb.save(path_export_final)\n",
    "    return None\n",
    "\n",
    "def fill_summary_sheet(summary_index_list,path_export_final):\n",
    "    print('Start fill summary sheet')\n",
    "    with xw.App(visible=False) as app:\n",
    "        wb_from = app.books.open(path_export_final)\n",
    "        summary_index = 1\n",
    "        for index in summary_index_list:\n",
    "            wb_from.sheets['Vendor Summary'].range('B'+str(summary_index+10)).value = index\n",
    "            summary_index += 1\n",
    "        length_start = summary_index + 10\n",
    "        range_length_to_remove = str(length_start)+':'+ str(30)\n",
    "        print(range_length_to_remove)\n",
    "        wb_from.sheets('Vendor Summary').range(range_length_to_remove).api.Delete(DeleteShiftDirection.xlShiftUp)         \n",
    "        wb_from.save(path_export_final)\n",
    "    return 'Done fill summary sheet' \n",
    "\n",
    "def create_worksheet(index_promo,gst,path_export_final):\n",
    "    # Open Excel in background\n",
    "    with xw.App(visible=False) as app:\n",
    "        if index_promo == 1:\n",
    "            wb_from = app.books.open(path_excel)\n",
    "        else :\n",
    "            wb_from = app.books.open(path_export_final)\n",
    "        ws_from = wb_from.sheets['template']\n",
    "        ws_from.copy(before=ws_from, name=str(index_promo)+'_'+str(gst))\n",
    "        wb_from.save(path_export_final)\n",
    "    return 'Done create worksheet'     \n",
    "\n",
    "def remove_sheet_change_xlsb(sheet_name,path_export_final,path_export_final_xlsb):\n",
    "    print('Start delete sheet & change to xlsb')\n",
    "    with xw.App(visible=False) as app:\n",
    "        wb = app.books.open(path_export_final)                \n",
    "        wb.sheets[sheet_name].delete()\n",
    "        wb.save(path_export_final_xlsb)\n",
    "    try:\n",
    "        os.remove(path_export_final)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return print('Done delete sheet & change to xlsb')\n",
    "\n",
    "# item_code=0,var_1=0,var_2=0,var_3=0,var_4=0\n",
    "\n",
    "def df_sales_data(item_list_dict_gsted,classify_state,supp_number_filter):\n",
    "    i = 0\n",
    "    print(classify_state)\n",
    "    if classify_state.lower() == 'state':\n",
    "        for key,value in item_list_dict_gsted.items():\n",
    "            print(key,value)\n",
    "            item_code,state = key\n",
    "            if np.isnan(supp_number_filter):\n",
    "                df_each_item = connect_sql(cursor,file_sql = file_sql_summ ,item_code = item_code,start_date = clm_start,end_date =clm_end,var_1=value[0],var_2=value[1])\n",
    "            else:\n",
    "                df_each_item = connect_sql(cursor,file_sql = file_sql_summ_vendor ,item_code = item_code,start_date = clm_start,end_date =clm_end,var_1=value[0],var_2 = supp_number_filter,var_3=value[1])\n",
    "            state_filter = state.replace(\"'\",'').split(',')\n",
    "            df_each_item = df_each_item[df_each_item['RSTATE'].isin(state_filter)]\n",
    "            if i == 0:\n",
    "                df_merge = df_each_item\n",
    "            else :\n",
    "                df_merge = pd.concat([df_merge, df_each_item], ignore_index=True)\n",
    "            i+=1\n",
    "        df_merge['ELI_CLAIM'] = df_merge.RQTY_PROMO * df_merge.SCAN_RATE\n",
    "        df_merge= df_merge.sort_values(by=['RSKU_ID','RDAY_DT','RSTATE'], ascending=True).reset_index(drop=True)\n",
    "    else:\n",
    "        for key,value in item_list_dict_gsted.items():\n",
    "            print(key,value)\n",
    "            if np.isnan(supp_number_filter):\n",
    "                df_each_item = connect_sql(cursor,file_sql = file_sql_summ ,item_code = key,start_date = clm_start,end_date =clm_end,var_1=value[0],var_2=value[1])\n",
    "            else:\n",
    "                df_each_item = connect_sql(cursor,file_sql = file_sql_summ_vendor ,item_code = key,start_date = clm_start,end_date =clm_end,var_1=value[0],var_2 = supp_number_filter,var_3=value[1])\n",
    "            if i == 0:\n",
    "                df_merge = df_each_item\n",
    "            else :\n",
    "                df_merge = pd.concat([df_merge, df_each_item], ignore_index=True)\n",
    "            i+=1\n",
    "        df_merge['ELI_CLAIM'] = df_merge.RQTY_PROMO * df_merge.SCAN_RATE\n",
    "        df_merge= df_merge.sort_values(by=['RSKU_ID','RDAY_DT','RSTATE'], ascending=True).reset_index(drop=True)\n",
    "    return df_merge\n",
    "\n",
    "def product_state_summary(df_sales,df_state_ref):\n",
    "    print('Start product_state_summary')\n",
    "    list_data = []\n",
    "    list_remove = []\n",
    "    # Find distict item_code and state\n",
    "    # writer_excel(df,cell_export,length_start,count_df,length_end,number_sheet,path_export_final)\n",
    "    df_temp =df_sales.drop_duplicates(['RSKU_ID','RITEM_DESC','RSTATE'])[['RSKU_ID','RITEM_DESC','RSTATE']]\n",
    "    df_temp_2 = pd.merge(df_temp,df_state_ref,left_on=['RSKU_ID','RSTATE'],right_on=['ITEM_IDNT','CLM_STATE'], how='left')\n",
    "    # print(df_ref)\n",
    "    df_final = df_temp_2[['RSKU_ID','RITEM_DESC','RSTATE','REF_NUM','CLM_QTY','CLM_RATE']]\n",
    "    df_sku_desc = df_final[['RSKU_ID','RITEM_DESC']]\n",
    "    df_state = df_final[['RSTATE']]\n",
    "    df_ref = df_final[['REF_NUM','CLM_QTY','CLM_RATE']]\n",
    "    df_ref.insert(1,\"REF_DESC\",'')\n",
    "    # Calculate number of rows\n",
    "    number_rows_state = len(df_ref)\n",
    "    dict_data_sku = {'df':df_sku_desc,'cell_export':'B121'}\n",
    "    dict_data_state = {'df':df_state,'cell_export':'E121'}\n",
    "    dict_data_remove = {'df':df_ref,'cell_export':'M121'}\n",
    "    dict_remove = {'count_df':number_rows_state,'length_start':121,'length_end':601}\n",
    "    list_data.append(dict_data_sku)\n",
    "    list_data.append(dict_data_state)\n",
    "    list_data.append(dict_data_remove)\n",
    "    list_remove.append(dict_remove)\n",
    "    print('Done product_state_summary')\n",
    "    return list_data,list_remove\n",
    "\n",
    "\n",
    "def product_summary(df_sales,df_item_ref):\n",
    "    print('Start product_summary')\n",
    "    list_data = []\n",
    "    list_remove = []\n",
    "    df_product =df_sales.drop_duplicates(['RSKU_ID','RITEM_DESC'])[['RSKU_ID','RITEM_DESC']]\n",
    "    df_temp = pd.merge(df_product,df_item_ref,left_on=['RSKU_ID'],right_on=['ITEM_IDNT'], how='left')\n",
    "    # df_final = df_temp[['RSKU_ID','RITEM_DESC','REF_NUM']]\n",
    "    df_product_1 = df_temp[['RSKU_ID','RITEM_DESC']]\n",
    "    df_ref_1 = df_temp[['REF_NUM']]\n",
    "    number_rows_sales = len(df_product)\n",
    "    # writer_excel(df = df_product,path_export_final = path_export_final, cell_export = 'B20',number_sheet = number_sheet,length_start=20 , count_df=number_rows_sales, length_end=116)\n",
    "    dict_data_sku = {'df':df_product_1,'cell_export':'B20'}\n",
    "    dict_data_ref = {'df':df_ref_1,'cell_export':'L20'}\n",
    "    dict_remove = {'count_df':number_rows_sales,'length_start':20,'length_end':116}\n",
    "    list_data.append(dict_data_sku)\n",
    "    list_data.append(dict_data_ref)\n",
    "    list_remove.append(dict_remove)\n",
    "    print('Done product_summary')\n",
    "    return list_data , list_remove\n",
    "\n",
    "def cd_ref(df_sales,supp_number_filter):\n",
    "    print('Start cd ref')\n",
    "    list_data = []\n",
    "    list_remove = []\n",
    "    df_ref = connect_sql(cursor,file_sql_cd_ref ,item_code = item_unique, start_date= clm_start , end_date= clm_end, var_1 = clm_start, var_2 = clm_end)\n",
    "    if np.isnan(supp_number_filter):\n",
    "        pass\n",
    "    else:\n",
    "        df_ref = df_ref[df_ref['CLM_SUPPLIER_MERCH'] == str(supp_number_filter)]\n",
    "    df_ref_groupby = df_ref.groupby('CLM_REF_NUM').agg({'CLM_PRODUCT':'sum'}).sort_values(by='CLM_PRODUCT', ascending=True).reset_index()\n",
    "    df_sales_daily = pd.concat([df_sales, df_ref_groupby], axis=1 )\n",
    "    print('Done cd ref')\n",
    "    print('start state ref')\n",
    "    df_state_ref = state_ref_groupby(df_ref)\n",
    "    print('done state ref')\n",
    "    print('start item ref')\n",
    "    df_item_ref = item_ref_groupby(df_ref)\n",
    "    print('done item ref')\n",
    "    # writer_excel(df = df_sales, cell_export = 'B174',number_sheet= str(index_promo)+'_'+str(gst),length_start=174 ,count_df=len(df_sales), length_end=10174,path_export_final=path_export_final)\n",
    "    dict_data = {'df':df_sales_daily,'cell_export':'B606'}\n",
    "    dict_remove = {'count_df':len(df_sales),'length_start':606,'length_end':20606}\n",
    "    list_data.append(dict_data)\n",
    "    list_remove.append(dict_remove)\n",
    "    return df_item_ref,df_state_ref,df_ref,df_sales_daily,list_data,list_remove\n",
    "\n",
    "def insert_attachments(sheet_name,file_path_excel,file_path_email,path_export_final):  \n",
    "    print('Start insert email and excel')\n",
    "    print(file_path_excel)\n",
    "    print(file_path_email)\n",
    "    xl = win32.gencache.EnsureDispatch('Excel.Application')\n",
    "    wb = xl.Workbooks.Open(fr'{current_dir}\\{path_export_final}', UpdateLinks = True)\n",
    "    ws = wb.Worksheets(sheet_name)\n",
    "    try:\n",
    "        excel_name = file_path_excel.split('/')[-1][0:20]\n",
    "    except:\n",
    "        excel_name = ''\n",
    "    try:\n",
    "        email_name = file_path_email.split('/')[-1][0:20]\n",
    "    except:\n",
    "        email_name = ''\n",
    "    obj = ws.OLEObjects()\n",
    "    xl.DisplayAlerts = False\n",
    "    #xl.AskToUpdateLinks = False\n",
    "    try:\n",
    "        obj.Add(ClassType=None, Filename=file_path_excel, Link=False, DisplayAsIcon=True, IconFileName=iconPath_excel,IconIndex=0, IconLabel = excel_name , Left=ws.Range(\"J8\").Left, Top=ws.Range(\"J8\").Top, Width=50, Height=50)\n",
    "        print(f'Successfully insert excel file in sheet {sheet_name}')\n",
    "    except com_error:\n",
    "        print(f'Cannot insert excel file in sheet {sheet_name}')\n",
    "        pass\n",
    "    try:\n",
    "        obj.Add(ClassType=None, Filename=file_path_email, Link=False, DisplayAsIcon=True, IconFileName=iconPath_email,IconIndex=0, IconLabel = email_name , Left= ws.Range(\"L8\").Left, Top=ws.Range(\"L8\").Top, Width=50, Height=50)\n",
    "        print(f'Successfully insert email file in sheet {sheet_name}')\n",
    "    except com_error:\n",
    "        print(f'Cannot insert email file in sheet {sheet_name}')\n",
    "        pass\n",
    "    xl.DisplayAlerts = True\n",
    "    #xl.AskToUpdateLinks = True\n",
    "    wb.Save()\n",
    "    wb.Close()\n",
    "    # xl.Application.Quit()\n",
    "    #del xl\n",
    "    print('Done insert email and excel')\n",
    "    return None\n",
    "\n",
    "def move_worksheet_to_vba_template(path_xlsb):\n",
    "    print('start move sheets')\n",
    "    with xw.App(visible=False) as app:\n",
    "        wb1 = app.books.open(path_xlsb)\n",
    "        wb2 = app.books.open(path_vba)\n",
    "        print(wb1.sheet_names)\n",
    "        for sheet_name in wb1.sheet_names:\n",
    "            ws1 = wb1.sheets(sheet_name)\n",
    "            ws1.api.Copy(Before=wb2.sheets('Sheet1').api)\n",
    "        wb2.sheets['Sheet1'].delete()\n",
    "        wb1.close()\n",
    "        wb2.save(path_xlsb)\n",
    "    print('end move sheets')\n",
    "    return None\n",
    "\n",
    "def list_to_listagg(x):\n",
    "    x = list(set(x))\n",
    "    x_convert = ','.join(x)\n",
    "    return x_convert\n",
    "\n",
    "def state_ref_groupby(df_ref):\n",
    "    df_ref_state_groupby = df_ref.groupby(by = ['ITEM_IDNT', 'CLM_STATE']).agg({'CLM_QTY':'sum','CLM_PRODUCT':'sum','CLM_REF_NUM':list}).reset_index()\n",
    "    df_ref_state_groupby['REF_NUM'] = df_ref_state_groupby['CLM_REF_NUM'].apply(lambda x : list_to_listagg(x))\n",
    "    df_ref_state_groupby['CLM_QTY'] = np.where(df_ref_state_groupby['CLM_QTY'].astype(int) != 0,df_ref_state_groupby['CLM_QTY'],np.nan) \n",
    "    df_ref_state_groupby['CLM_RATE'] = (df_ref_state_groupby['CLM_PRODUCT'] / df_ref_state_groupby['CLM_QTY']).astype('float').round(2)\n",
    "    df_ref_state_groupby = df_ref_state_groupby[['ITEM_IDNT', 'CLM_STATE', 'CLM_QTY', 'CLM_RATE', 'CLM_PRODUCT', 'REF_NUM']]\n",
    "    return df_ref_state_groupby\n",
    "\n",
    "def item_ref_groupby(df_ref):\n",
    "    df_ref_item_groupby = df_ref.groupby(by = ['ITEM_IDNT']).agg({'CLM_QTY':'sum','CLM_PRODUCT':'sum','CLM_REF_NUM':list}).reset_index()\n",
    "    df_ref_item_groupby['REF_NUM'] = df_ref_item_groupby['CLM_REF_NUM'].apply(lambda x : list_to_listagg(x))\n",
    "    df_ref_item_groupby['CLM_QTY'] = np.where(df_ref_item_groupby['CLM_QTY'].astype(int) != 0,df_ref_item_groupby['CLM_QTY'],np.nan) \n",
    "    df_ref_item_groupby['CLM_RATE'] = (df_ref_item_groupby['CLM_PRODUCT'] / df_ref_item_groupby['CLM_QTY']).astype('float').round(2)\n",
    "    df_ref_item_groupby = df_ref_item_groupby[['ITEM_IDNT', 'CLM_QTY', 'CLM_RATE', 'CLM_PRODUCT', 'REF_NUM']]\n",
    "    return df_ref_item_groupby\n",
    "\n",
    "\n",
    "#MAIN\n",
    "print('START')\n",
    "cursor = set_up(config = config_coles)\n",
    "excel_file = pd.ExcelFile(path_import_item)\n",
    "count_sheets_excel_file = len(excel_file.sheet_names)\n",
    "# excel_file.close()\n",
    "summary_index_list =[]\n",
    "for i in range(1,count_sheets_excel_file+1):\n",
    "    print(f'Sheet {i}')\n",
    "    supp_num,supp_desc,vendor_num,supp_number_filter,claim_number,gst,clm_start,clm_end,dept,item_unique,item_list_dict,classify_state,file_path_excel,file_path_email = item_gst(i)\n",
    "    df_sales = df_sales_data(item_list_dict,classify_state,supp_number_filter)\n",
    "    df_item_ref,df_state_ref,df_ref,df_sales_daily,list_data_sales,list_remove_sales  = cd_ref(df_sales,supp_number_filter)\n",
    "    if df_ref.empty:\n",
    "        prmt_id = ''\n",
    "        prmt_name = ''\n",
    "    else:\n",
    "        prmt_id = df_ref['PRMTN_COMP_IDNT'][0]\n",
    "        prmt_name = df_ref['PRMTN_COMP_NAME'][0]\n",
    "    dict_data_dept = {'df':dept,'cell_export':'F8'}\n",
    "    dict_data_supp_num = {'df':supp_num,'cell_export':'E8'}\n",
    "    dict_data_supp_desc = {'df':supp_desc,'cell_export':'C8'}\n",
    "    dict_data_vendor_num = {'df':vendor_num,'cell_export':'D8'}\n",
    "    dict_data_claim_number = {'df': claim_number,'cell_export':'B16'}\n",
    "    dict_data_prmt_id = {'df':prmt_id,'cell_export':'B12'}\n",
    "    dict_data_prmt_name = {'df':prmt_name,'cell_export':'C12'}\n",
    "    list_data_state,list_remove_state = product_state_summary(df_sales,df_state_ref)\n",
    "    list_data_product ,list_remove_product = product_summary(df_sales,df_item_ref)\n",
    "    list_data = list_data_sales + list_data_state + list_data_product + [dict_data_dept] + [dict_data_prmt_id] + [dict_data_prmt_name] +  [dict_data_supp_num] + [dict_data_supp_desc] + [dict_data_vendor_num] + [dict_data_claim_number]\n",
    "    list_remove = list_remove_sales + list_remove_state + list_remove_product\n",
    "    create_worksheet(i,gst,path_export_final)\n",
    "    writer_excel(list_data,list_remove,claim_number,path_export_final)\n",
    "    try:\n",
    "        insert_attachments(str(i)+'_'+str(gst),file_path_excel,file_path_email,path_export_final)\n",
    "    except:\n",
    "        pass\n",
    "    summary_index_list.append(claim_number)\n",
    "fill_summary_sheet(summary_index_list,path_export_final=path_export_final) \n",
    "remove_sheet_change_xlsb(sheet_name = 'template',path_export_final=path_export_final ,path_export_final_xlsb = path_export_final_xlsb)\n",
    "move_worksheet_to_vba_template(path_export_final_xlsb)\n",
    "\n",
    "# xl.Application.Quit()\n",
    "print('END')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fa8299f20a01bb8560ebc0db582b7ed77a2c0ddde0b2c0251417c7c412141a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
